{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks using PyTorch\n",
    "See also the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#sphx-glr-beginner-nlp-deep-learning-tutorial-py)\n",
    "\n",
    "We want to model\n",
    "\n",
    "$$f(\\mathbf{x}) = \\mathbf{A}x + \\mathbf{b}$$\n",
    "\n",
    "where the vector $\\mathbf{x}$ is the input and the matrix and vector $\\mathbf{A}$ and $\\mathbf{b}$ are the parameters $\\Theta$ that we want to learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study\n",
    "We aim at training a network for guessing the correct word having as input an arbitrary string of characters (useful for spelling correction for example).\n",
    "\n",
    "### Input and output\n",
    "The output is a set of words (or *phrase words* such as 'you are'), represented as a one-hot vector $\\mathbf{w}$ of size $V$, having $V$ the size of the vocabulary.\n",
    "The input is a set of strings. Each string is represented as a matrix of characters $\\mathbf{C} \\in \\mathbb{R}^{28 \\times 28}$, where the 28 dimensions correspond to one ascii lowercase character plus a dimension for whitespace and another dimension for any other character.\n",
    "\n",
    "Each entry $[c_{ij}]$ represents a bigram which states that the character $j$ is the character that follows $i$ in the string. Given an input string $s$, we calcuate:\n",
    "\n",
    "$$[c_{ij}] = \\frac{count(c_i, c_j)}{\\max\\limits_{c_x, c_y \\in s} count(c_x, c_y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = string.ascii_lowercase + string.whitespace + '#'\n",
    "CHAR_INDEX = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    out = \"\"\n",
    "    for c in s.lower():\n",
    "        if c in CHAR_INDEX.keys():\n",
    "            out += c\n",
    "        else:\n",
    "            out += '#'\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_matrix(s, n=2):\n",
    "    z = preprocess(s)\n",
    "    C = np.zeros((len(CHAR_INDEX), len(CHAR_INDEX)))\n",
    "    for a, b in nltk.ngrams(z, n=n):\n",
    "        C[CHAR_INDEX[a], CHAR_INDEX[b]] += 1\n",
    "    C /= C.max()\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_string(s, ax, n=2):\n",
    "    S = string_to_matrix(s, n=n)\n",
    "    ax.imshow(S, cmap='Greys')\n",
    "    ax.set_title(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = [['play', 'plays', 'playing'], ['you are', \"you're\", 'yours']]\n",
    "fig, ax = plt.subplots(figsize=(10, 6), ncols=len(example[0]), nrows=len(example))\n",
    "for i, words in enumerate(example):\n",
    "    for j, w in enumerate(words):\n",
    "        visualize_string(w, ax[i,j], n=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions\n",
    "For a given string, the input is a vector $\\mathbf{x} \\in \\mathbb{R}^{28 \\times 28 = 784}$ dimensions obtained by concatenating the rows of the string characters matrix. The output will be another vector $\\mathbf{\\hat{y}} \\in \\mathbb{R}^V$. But, since we want the output to be a probability distribution, we apply a non-linear transformation to $f(\\mathbf{x})$ called *Softmax*:\n",
    "\n",
    "$$\n",
    "softmax(\\mathbf{\\hat{y}}) = \\frac{\\exp(\\mathbf{\\hat{y}}_i)}{\\sum\\limits_{j=1}^{V} \\exp(\\mathbf{\\hat{y}}_j)}\n",
    "$$\n",
    "\n",
    "so that the complete non-linear transformation is\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{y}} = softmax(\\mathbf{A}x + \\mathbf{b})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Given a **loss function** $L(\\Theta)$ and a learning parameter $\\eta$, training in this example is performed by gradient update as\n",
    "\n",
    "$$\n",
    "\\Theta^t = \\Theta^{t-1} - \\eta \\nabla_{\\Theta} L(\\Theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8dbe66b970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import gettext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['ITA', 'FRA', 'USA', 'DEU', 'GBR', 'ESP', 'IND', 'CHN']\n",
    "languages = ['de', 'it', 'fr']\n",
    "translator = {}\n",
    "for lang in languages:\n",
    "    translator[lang] = gettext.translation(\n",
    "        'iso3166', pycountry.LOCALES_DIR, languages=[lang])\n",
    "    translator[lang].install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_names(country, translator):\n",
    "    names = []\n",
    "    c = pycountry.countries.get(alpha_3=country)\n",
    "    names.append(c.name)\n",
    "    names.append(c.official_name)\n",
    "    for _, t in translator.items():\n",
    "        names.append(t.gettext(c.name))\n",
    "        names.append(t.gettext(c.official_name))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Italy',\n",
       " 'Italian Republic',\n",
       " 'Italien',\n",
       " 'Italienische Republik',\n",
       " 'Italia',\n",
       " 'Repubblica italiana',\n",
       " 'Italie',\n",
       " 'République italienne']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country_names('ITA', translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "training_data, testing_data = [], []\n",
    "for country in countries:\n",
    "    names = get_country_names(country, translator)\n",
    "    np.random.shuffle(names)\n",
    "    training_data.append((names[:6], country))\n",
    "    testing_data.append((names[6:], country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = len(countries)\n",
    "V = len(CHAR_INDEX) * len(CHAR_INDEX)\n",
    "LABEL_INDEX = dict((l, i) for i, l in enumerate(countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2Gram(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_labels, size):\n",
    "        super(Simple2Gram, self).__init__()\n",
    "        self.linear = nn.Linear(size, num_labels)\n",
    "    \n",
    "    def forward(self, vec):\n",
    "        return F.log_softmax(self.linear(vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(s, n=2):\n",
    "    vec = torch.tensor(string_to_matrix(s, n=n)).float()\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def target(label):\n",
    "    return torch.LongTensor([LABEL_INDEX[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple2Gram(N_LABELS, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0232,  0.0252, -0.0071,  ...,  0.0276,  0.0177, -0.0157],\n",
      "        [-0.0300,  0.0115,  0.0170,  ..., -0.0122,  0.0145,  0.0083],\n",
      "        [-0.0116,  0.0185, -0.0097,  ..., -0.0171, -0.0184,  0.0082],\n",
      "        ...,\n",
      "        [ 0.0020, -0.0153, -0.0293,  ..., -0.0090, -0.0055, -0.0013],\n",
      "        [ 0.0020,  0.0133,  0.0229,  ..., -0.0209, -0.0280, -0.0164],\n",
      "        [ 0.0227,  0.0297, -0.0125,  ..., -0.0215,  0.0244, -0.0138]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0033,  0.0102, -0.0202, -0.0028, -0.0102, -0.0072, -0.0110,  0.0194],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = training_data[0]\n",
    "    vec = vector(sample[0][0], n=2)\n",
    "    log_probs = model(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0550, -2.1113, -2.0846, -2.0265, -2.0686, -2.0346, -2.1369, -2.1240]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    for samples, label in training_data:\n",
    "        for instance in samples:\n",
    "            model.zero_grad()\n",
    "            vec = vector(instance)\n",
    "            tar = target(label)\n",
    "            log_probs = model(vec)\n",
    "            L = loss(log_probs, tar)\n",
    "            L.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0867, -3.7281, -5.6357, -3.7958, -6.2628, -5.7536, -4.7324, -3.9575]])\n",
      "Input string: Repubblica italiana\n",
      "Guess: ITA \n",
      "\n",
      "tensor([[-2.8245e-03, -8.9713e+00, -6.6289e+00, -7.8520e+00, -8.6481e+00,\n",
      "         -7.8297e+00, -8.4382e+00, -8.5514e+00]])\n",
      "Input string: Italie\n",
      "Guess: ITA \n",
      "\n",
      "tensor([[-7.1828, -0.0118, -6.6689, -5.5574, -6.5041, -5.8338, -7.5196, -6.9884]])\n",
      "Input string: France\n",
      "Guess: FRA \n",
      "\n",
      "tensor([[-6.7375, -0.0452, -6.7888, -4.5870, -4.1623, -4.6080, -7.6277, -5.1655]])\n",
      "Input string: Frankreich\n",
      "Guess: FRA \n",
      "\n",
      "tensor([[-4.7247, -5.3044, -0.1413, -5.3274, -2.7025, -3.9635, -4.6738, -4.0364]])\n",
      "Input string: Vereinigte Staaten\n",
      "Guess: USA \n",
      "\n",
      "tensor([[-6.0302, -7.3207, -0.0168, -5.4985, -5.2610, -6.0179, -7.0175, -6.9345]])\n",
      "Input string: Stati Uniti d'America\n",
      "Guess: USA \n",
      "\n",
      "tensor([[-6.3989, -5.7159, -5.8503, -0.0184, -5.9888, -5.3952, -6.8719, -6.0612]])\n",
      "Input string: Germany\n",
      "Guess: DEU \n",
      "\n",
      "tensor([[-3.7335, -6.0816, -5.1450, -0.1384, -5.1220, -2.5337, -5.9620, -4.6730]])\n",
      "Input string: Allemagne\n",
      "Guess: DEU \n",
      "\n",
      "tensor([[-4.6130, -4.5089, -3.8662, -2.7855, -0.2925, -2.1505, -4.1840, -3.9958]])\n",
      "Input string: Regno Unito di Gran Bretagna e d'Irlanda del Nord\n",
      "Guess: GBR \n",
      "\n",
      "tensor([[-3.2509, -4.5045, -1.7046, -4.3497, -0.6650, -1.4774, -5.6611, -4.6625]])\n",
      "Input string: Regno Unito\n",
      "Guess: GBR \n",
      "\n",
      "tensor([[-7.9112, -8.2623, -7.1249, -5.9098, -2.7735, -0.0717, -7.6461, -6.1339]])\n",
      "Input string: Royaume d'Espagne\n",
      "Guess: ESP \n",
      "\n",
      "tensor([[-4.6828, -4.5250, -3.9616, -4.7127, -3.0387, -0.4014, -2.1852, -2.1024]])\n",
      "Input string: Kingdom of Spain\n",
      "Guess: ESP \n",
      "\n",
      "tensor([[-6.4493, -6.8198, -6.5790, -6.0221, -5.7444, -5.8815, -0.0190, -5.0541]])\n",
      "Input string: India\n",
      "Guess: IND \n",
      "\n",
      "tensor([[-5.6012, -6.4943, -6.1952, -6.6316, -5.6470, -4.0061, -0.0378, -4.9934]])\n",
      "Input string: Indien\n",
      "Guess: IND \n",
      "\n",
      "tensor([[-5.6243, -5.4823, -5.6117, -5.5827, -5.0998, -4.6433, -4.5066, -0.0429]])\n",
      "Input string: Chine\n",
      "Guess: CHN \n",
      "\n",
      "tensor([[ -6.6278,  -5.2778, -10.0452,  -6.1806,  -7.9242,  -9.2134,  -6.1524,\n",
      "          -0.0112]])\n",
      "Input string: People's Republic of China\n",
      "Guess: CHN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for test, label in testing_data:\n",
    "        for word in test:\n",
    "            vec = vector(word, n=2)\n",
    "            log_probs = model(vec)\n",
    "            print(log_probs)\n",
    "            print('Input string:', word)\n",
    "            prediction = np.argmax(log_probs.numpy())\n",
    "            print('Guess:', countries[prediction], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = lambda x: Categorical(probs=x).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for test, label in testing_data:\n",
    "        for word in test:\n",
    "            vec = vector(word, n=2)\n",
    "            predictions.append(model(vec))\n",
    "            y_true.append(LABEL_INDEX[label])\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = sum([entropy(p) for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31.0245])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(p.numpy()) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ITA       1.00      1.00      1.00         2\n",
      "         FRA       1.00      1.00      1.00         2\n",
      "         USA       1.00      1.00      1.00         2\n",
      "         DEU       1.00      1.00      1.00         2\n",
      "         GBR       1.00      1.00      1.00         2\n",
      "         ESP       1.00      1.00      1.00         2\n",
      "         IND       1.00      1.00      1.00         2\n",
      "         CHN       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make things harder\n",
    "In the following we simulate some spelling errors to see if the network can handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_chars(s, substitutions=2):\n",
    "    w = list(s)\n",
    "    for iteration in range(substitutions):\n",
    "        n = np.random.choice(list(string.ascii_lowercase))\n",
    "        i = np.random.randint(0, len(w))\n",
    "        w[i] = n\n",
    "    return \"\".join(w)\n",
    "\n",
    "def add_chars(s, additions=2):\n",
    "    w = list(s)\n",
    "    for iteration in range(additions):\n",
    "        n = np.random.choice(list(string.ascii_lowercase))\n",
    "        i = np.random.randint(0, len(w))\n",
    "        w = w[:i] + list(n) + w[i:]\n",
    "    return \"\".join(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test, h = [], 3\n",
    "for test, label in testing_data:\n",
    "    nk = []\n",
    "    for word in test:\n",
    "        nk.append(substitute_chars(word, substitutions=h))\n",
    "        nk.append(add_chars(word, additions=h))\n",
    "    h_test.append((test + nk, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for test, label in h_test:\n",
    "        for word in test:\n",
    "            vec = vector(word, n=2)\n",
    "            predictions.append(model(vec))\n",
    "            y_true.append(LABEL_INDEX[label])\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([93.9197])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([entropy(p) for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(p.numpy()) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ITA       0.86      1.00      0.92         6\n",
      "         FRA       1.00      1.00      1.00         6\n",
      "         USA       1.00      1.00      1.00         6\n",
      "         DEU       1.00      1.00      1.00         6\n",
      "         GBR       1.00      0.83      0.91         6\n",
      "         ESP       0.86      1.00      0.92         6\n",
      "         IND       0.67      0.67      0.67         6\n",
      "         CHN       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.92        48\n",
      "   macro avg       0.92      0.92      0.92        48\n",
      "weighted avg       0.92      0.92      0.92        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/spelling_correction_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for sample, label in testing_data:\n",
    "    for word in sample:\n",
    "        vectors.append(vector(word).numpy())\n",
    "X = torch.tensor(np.array(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, X)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
