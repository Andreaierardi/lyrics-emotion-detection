{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long Example 0: Text classification with pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How samples are split in Scikit-learn $K$-fold CV\n"
   ]
  },
  {
   "source": [
    "EXECUTED"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn libraries\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "# create the range 1 to 14\n",
    "rn = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "print(rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to demonstrate how the data are split, we will create 3 and 5 folds. \n",
    "# KFold function has to be applied on the data and it returns an \n",
    "# location (index) of the train and test samples.\n",
    "kf5 = KFold(n_splits=5, shuffle=False)\n",
    "kf3 = KFold(n_splits=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 5  6  7  8  9 10 11 12 13] [0 1 2 3 4]\n[ 0  1  2  3  4 10 11 12 13] [5 6 7 8 9]\n[0 1 2 3 4 5 6 7 8 9] [10 11 12 13]\n"
     ]
    }
   ],
   "source": [
    "# The Kfold function retunrs the indices of the data. \n",
    "# Our range goes from 1-14 so the index is 0-13\n",
    "for train_index, test_index in kf3.split(rn):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment: we have here that n/k is 14/3, which is 4 with a reminder r=2.\n",
    "# The two reminder elements are assigned to the first two test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 3  4  5  6  7  8  9 10 11 12 13] [0 1 2]\n[ 0  1  2  6  7  8  9 10 11 12 13] [3 4 5]\n[ 0  1  2  3  4  5  9 10 11 12 13] [6 7 8]\n[ 0  1  2  3  4  5  6  7  8 12 13] [ 9 10 11]\n[ 0  1  2  3  4  5  6  7  8  9 10 11] [12 13]\n"
     ]
    }
   ],
   "source": [
    "# K=5 folds:\n",
    "for train_index, test_index in kf5.split(rn):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Therefore the splitting is done by taking the value of the reminder r and \n",
    "#assigning one further element to each fold until r-th fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines in scikit-learn (1)\n",
    "\n",
    "- We spent a lot of time in pre-processing and cleaning data\n",
    "- Therefore we need to create multipurpose software objects to be used in diffirent situations.\n",
    "- For this we can use the Pipeline tool in scikit-learn.\n",
    "- It is composed by *transformers* (tools for transforming data, for example to normalize a variable) and *estimators* (for example a fitting or predicting tool).\n",
    "- All transformers and estimators in scikit-learn are implemented as Python *classes*, each with their own attributes and methods.\n",
    "- We use *inherited* classes from scikit-learn to implement our own class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pipeline.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of inheritance\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "#Some data:\n",
    "X = [[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]\n",
    "#Initializing an object of class OneHotEncoder\n",
    "# Here we are \"inheriting\" classes from OneHotEncoder into the variable 'one_hot_enc'\n",
    "one_hot_enc = OneHotEncoder( sparse = True )\n",
    "\n",
    "#Calling methods on our OneHotEncoder object\n",
    "one_hot_enc.fit( X ) #returns nothing\n",
    "transformed_data = one_hot_enc.transform(X).toarray() #returns something\n",
    "#fit_transformed_data = one_hot_enc.transform( X ) #returns something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0  1  2\n0  0  0  3\n1  1  1  0\n2  0  2  1\n3  1  0  2\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X))\n",
    "#Comments: The first column takes on 2 values, the second 3 and the fourth 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 1. 0. 0. 0. 0. 0. 1.]\n [0. 1. 0. 1. 0. 1. 0. 0. 0.]\n [1. 0. 0. 0. 1. 0. 1. 0. 0.]\n [0. 1. 1. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(transformed_data)\n",
    "#Comments: the first two columns express the binary coding of the first \"feature\"; \n",
    "# the next three columns express the binary coding of the second \"feature\";\n",
    "# The next four columns express the binary coding of the third \"feature\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines in scikit-learn (2)\n",
    "\n",
    "- Our own trasformer will be formed by inheriting from some other scikit-learn class.\n",
    "- See a tutorial here https://www.programiz.com/python-programming/class about classes and objects in python and a tutorial here https://www.programiz.com/python-programming/inheritance about inheritance.\n",
    "- The base classes inherited from scikit-learn are TransformerMixin (https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) and BaseEstimator (https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           v1  \\\n",
       "0    positive   \n",
       "1    positive   \n",
       "2    negative   \n",
       "3    positive   \n",
       "4    positive   \n",
       "..        ...   \n",
       "995  negative   \n",
       "996  positive   \n",
       "997  positive   \n",
       "998  positive   \n",
       "999  positive   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   v2  \n",
       "0    When I had problems with the return of the bike, the assistance was very kind, but could not solve the problem quickly nor prevent me from being charged for the rental because I had exceeded half an hour (not because of the route I took carried out, but due to the impossibility of hanging up the bike in 2 different stations). It would be desirable to be able to solve problems more efficiently or at least not to charge the user in the event of a reported malfunction. For the rest, when the service works, it's really practical and useful.\\t  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                        more electric bikes. often even if present they are not available when there are few, why?\\t  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                  pay more attention to stations that very often are without bicycles or full and do not allow their repositioning\\t  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        essential to insert bikes with child seats\\t  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    extension completed at train and metro stations not yet served\\t  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ...  \n",
       "995                                                                                                                                                                                                                                                                                                                                                                                                               Main problem I think is the maintenance of traditional bikes, often you are forced to change bikes several times before finding a functioning one\\t  \n",
       "996                                                                                                                                                                                                                                                                                                                                                                                                              I feel good but without a credit card you can't even buy a day card, it doesn't seem right because students like me often only have a prepaid card\\t  \n",
       "997                                                                                                                                                                                                                                                                                                                                                                                                                                                          I don't have any suggestions at the moment. the comment, thank you for the excellent service provided.\\t  \n",
       "998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I would like it if the number of red ebikes increased considerably\\t  \n",
       "999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               need more maintenance, stations in the center with too many bikes\\t  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>positive</td>\n      <td>When I had problems with the return of the bike, the assistance was very kind, but could not solve the problem quickly nor prevent me from being charged for the rental because I had exceeded half an hour (not because of the route I took carried out, but due to the impossibility of hanging up the bike in 2 different stations). It would be desirable to be able to solve problems more efficiently or at least not to charge the user in the event of a reported malfunction. For the rest, when the service works, it's really practical and useful.\\t</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>positive</td>\n      <td>more electric bikes. often even if present they are not available when there are few, why?\\t</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>pay more attention to stations that very often are without bicycles or full and do not allow their repositioning\\t</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positive</td>\n      <td>essential to insert bikes with child seats\\t</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>positive</td>\n      <td>extension completed at train and metro stations not yet served\\t</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>negative</td>\n      <td>Main problem I think is the maintenance of traditional bikes, often you are forced to change bikes several times before finding a functioning one\\t</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>positive</td>\n      <td>I feel good but without a credit card you can't even buy a day card, it doesn't seem right because students like me often only have a prepaid card\\t</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>positive</td>\n      <td>I don't have any suggestions at the moment. the comment, thank you for the excellent service provided.\\t</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>positive</td>\n      <td>I would like it if the number of red ebikes increased considerably\\t</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>positive</td>\n      <td>need more maintenance, stations in the center with too many bikes\\t</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Load Data\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "BikeSent = pd.read_csv(\"BikeMiSentiment2019_UTF-8.csv\", sep=';')\n",
    "BikeSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     target  \\\n",
       "0  positive   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  positive   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \n",
       "0  When I had problems with the return of the bike, the assistance was very kind, but could not solve the problem quickly nor prevent me from being charged for the rental because I had exceeded half an hour (not because of the route I took carried out, but due to the impossibility of hanging up the bike in 2 different stations). It would be desirable to be able to solve problems more efficiently or at least not to charge the user in the event of a reported malfunction. For the rest, when the service works, it's really practical and useful.\\t  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                      more electric bikes. often even if present they are not available when there are few, why?\\t  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                pay more attention to stations that very often are without bicycles or full and do not allow their repositioning\\t  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      essential to insert bikes with child seats\\t  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  extension completed at train and metro stations not yet served\\t  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>positive</td>\n      <td>When I had problems with the return of the bike, the assistance was very kind, but could not solve the problem quickly nor prevent me from being charged for the rental because I had exceeded half an hour (not because of the route I took carried out, but due to the impossibility of hanging up the bike in 2 different stations). It would be desirable to be able to solve problems more efficiently or at least not to charge the user in the event of a reported malfunction. For the rest, when the service works, it's really practical and useful.\\t</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>positive</td>\n      <td>more electric bikes. often even if present they are not available when there are few, why?\\t</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>pay more attention to stations that very often are without bicycles or full and do not allow their repositioning\\t</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positive</td>\n      <td>essential to insert bikes with child seats\\t</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>positive</td>\n      <td>extension completed at train and metro stations not yet served\\t</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Rename columns\n",
    "BikeSent.columns = [\"target\", \"text\"]\n",
    "BikeSent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       0   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \n",
       "0  When I had problems with the return of the bike, the assistance was very kind, but could not solve the problem quickly nor prevent me from being charged for the rental because I had exceeded half an hour (not because of the route I took carried out, but due to the impossibility of hanging up the bike in 2 different stations). It would be desirable to be able to solve problems more efficiently or at least not to charge the user in the event of a reported malfunction. For the rest, when the service works, it's really practical and useful.\\t  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                      more electric bikes. often even if present they are not available when there are few, why?\\t  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                pay more attention to stations that very often are without bicycles or full and do not allow their repositioning\\t  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      essential to insert bikes with child seats\\t  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  extension completed at train and metro stations not yet served\\t  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When I had problems with the return of the bike, the assistance was very kind, but could not solve the problem quickly nor prevent me from being charged for the rental because I had exceeded half an hour (not because of the route I took carried out, but due to the impossibility of hanging up the bike in 2 different stations). It would be desirable to be able to solve problems more efficiently or at least not to charge the user in the event of a reported malfunction. For the rest, when the service works, it's really practical and useful.\\t</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>more electric bikes. often even if present they are not available when there are few, why?\\t</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>pay more attention to stations that very often are without bicycles or full and do not allow their repositioning\\t</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>essential to insert bikes with child seats\\t</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>extension completed at train and metro stations not yet served\\t</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Encode categories\n",
    "BikeSent['target'] = np.where(BikeSent['target']=='positive',1,0)\n",
    "BikeSent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sample in train (used also for cross-validation) + test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X = BikeSent[['text']]\n",
    "y = BikeSent['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                               text\n",
       "716  Luckily I have tried the new bicycle models a few times and they are definitely uncomfortable. I think there is a design error because the saddle is too far forward and you have difficulty pedaling. I hope you realize this before increasing the number of bikes you buy\\t\n",
       "351                                                                                                                                                                                       Improve the bike pickup and storage system. For older people they are too heavy to lift\\t\n",
       "936                           I kindly ask you to make the stall n. 151 Balilla - Tibaldi. Sometimes it is uninhabitable and there are few bicycles available or they are generally few or poorly functioning (eg deflated wheels, poorly functioning brakes, gearshift changes).\\t\n",
       "256                                                                                                                bikes should be maintained much, much better, often with badly maintained bicycles and without brakes or even for the electrics that the battery does not work\\t\n",
       "635                                                                                                                                                                                                                                                          Increase maintenance\\t\n",
       "..                                                                                                                                                                                                                                                                              ...\n",
       "106                                                                  A really useful service, I hope in the possibility of using 24 hours a day, especially for us young people it can be very useful at night when the vehicles are almost zero and you are forced to use taxis.\\t\n",
       "270                                                                                                                                          only problem to report too often the stalls do not record the correct establishment of the bike and you risk icorrerere nela penalty\\t\n",
       "860                                                                   Some discounts for the renewal of the subscription. The offers seem to me always and only for the new subscribers. In addition, a few more conventions for Bikemi subscribers who give discounts elsewhere.\\t\n",
       "435                                                                                                                 the service is smart but is very limited by the location of the stations. They are all a center. There isn't one in Stazione Lambrate or the eastern suburbs.\\t\n",
       "102                                                                                                                                                                                                                                                                          good\\t\n",
       "\n",
       "[900 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>716</th>\n      <td>Luckily I have tried the new bicycle models a few times and they are definitely uncomfortable. I think there is a design error because the saddle is too far forward and you have difficulty pedaling. I hope you realize this before increasing the number of bikes you buy\\t</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>Improve the bike pickup and storage system. For older people they are too heavy to lift\\t</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>I kindly ask you to make the stall n. 151 Balilla - Tibaldi. Sometimes it is uninhabitable and there are few bicycles available or they are generally few or poorly functioning (eg deflated wheels, poorly functioning brakes, gearshift changes).\\t</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>bikes should be maintained much, much better, often with badly maintained bicycles and without brakes or even for the electrics that the battery does not work\\t</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>Increase maintenance\\t</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>A really useful service, I hope in the possibility of using 24 hours a day, especially for us young people it can be very useful at night when the vehicles are almost zero and you are forced to use taxis.\\t</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>only problem to report too often the stalls do not record the correct establishment of the bike and you risk icorrerere nela penalty\\t</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>Some discounts for the renewal of the subscription. The offers seem to me always and only for the new subscribers. In addition, a few more conventions for Bikemi subscribers who give discounts elsewhere.\\t</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>the service is smart but is very limited by the location of the stations. They are all a center. There isn't one in Stazione Lambrate or the eastern suburbs.\\t</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>good\\t</td>\n    </tr>\n  </tbody>\n</table>\n<p>900 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cleaning Text\n",
    "- We create here our own transformer (which will be a class) inheriting the TransformerMixin and the BaseEstimator classes from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Custom Transformer (Inheriting from classes)\n",
    "class CleanText( BaseEstimator, TransformerMixin ):\n",
    "    \n",
    "    # Class Constructor \n",
    "    # The class constructor is formed by a function with double underscore __ :\n",
    "    # these are called 'special functions' as they have special meaning.\n",
    "    # In particular the '__init__' gets called whenever \n",
    "    # a new object of that class is instantiated,\n",
    "    # and are used to initialize all the necessary variables.\n",
    "    # In this example we initialize the language variable 'lang' with 'English'\n",
    "    # and pick the SnowballStemmer as the default stemmer.\n",
    "    def __init__( self, lang = \"english\"):\n",
    "        self.lang = lang\n",
    "        self.stemmer = SnowballStemmer(self.lang)\n",
    "    \n",
    "    # The 'fit' method here is used to instantiate the class on the 'self' variable \n",
    "    # and return the object itself     \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    # Custom function: this applies the stemmer just created in the '__init__'\n",
    "    # part to the 'self' variable\n",
    "    def clean( self, x ):\n",
    "        words   = [self.stemmer.stem(word) for word in word_tokenize(x.lower()) if word.isalpha() and word not in stopwords.words(\"english\")]\n",
    "        return \" \".join(words)\n",
    "    \n",
    "    # Method that describes what we need this transformer to do i.e. cleaning the text\n",
    "    # in the 'text' column in the data frame.\n",
    "    # This will be used later on in the usage of the custom transformer \n",
    "    # within the pipeline.\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[\"text\"].apply(self.clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer: same parts as the previous custom transformer\n",
    "# This one will be used for feature extraction\n",
    "\n",
    "class CustomFeatures( BaseEstimator, TransformerMixin ):\n",
    "    \n",
    "    # Class Constructor \n",
    "    def __init__( self ):\n",
    "        return\n",
    "    \n",
    "    # Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "        \n",
    "    # Method that describes what we need this transformer to do i.e.\n",
    "    # returning length, digits and punctuations in the 'text' column in data frame\n",
    "    def transform( self, X, y = None ):\n",
    "        f           = pd.DataFrame()\n",
    "        f['len']    = X['text'].str.len()\n",
    "        f['digits'] = X['text'].str.findall(r'\\d').str.len()\n",
    "        f['punct']  = X['text'].str.findall(r'[^a-zA-Z\\d\\s:]').str.len()\n",
    "        return f[['len','digits','punct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "# FeatureUnion combines two or more pipelines or transformers\n",
    "# and is very fast!\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Our first pipeline called 'pipe' will be formed by three 'steps' or parts:\n",
    "# 1)\"extract\" which in turns is formed through FeatureUnion which put together two parts:\n",
    "# \"terms\" (formed by a pipeline with the CleanText() transformer we created above\n",
    "# and the TfidVectorize text vectorizing transformer from scikit-learn) and \"custom\" \n",
    "# (formed by the CustomFeatures transformer we created above);\n",
    "# 2) \"select\", formed by the scikit-learn transformer method \"SelectKBest\" for feature \n",
    "# selection with a chi squared score function;\n",
    "# 3) \"scale\", same as 2) using the StandardScaler method from scikit-learn. \n",
    "# The whole pipeline will be used as pre-processing task in classifying pipelines.\n",
    "pipe = Pipeline([(\"extract\", FeatureUnion([(\"terms\", Pipeline([('clean', CleanText()), \n",
    "                                                               ('tfidf', TfidfVectorizer())])),\n",
    "                                           (\"custom\", CustomFeatures())])),\n",
    "                 (\"select\", SelectKBest(score_func = chi2)),\n",
    "                 (\"scale\", StandardScaler(with_mean = False))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier implemented through pipelines: Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\AndreDany\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\AndreDany\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Model\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe_logistic = Pipeline([('pre_process', pipe),\n",
    "                          ('classify', LogisticRegression(max_iter=10000, tol=0.1, solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pre_process',\n",
       "                 Pipeline(steps=[('extract',\n",
       "                                  FeatureUnion(transformer_list=[('terms',\n",
       "                                                                  Pipeline(steps=[('clean',\n",
       "                                                                                   CleanText()),\n",
       "                                                                                  ('tfidf',\n",
       "                                                                                   TfidfVectorizer())])),\n",
       "                                                                 ('custom',\n",
       "                                                                  CustomFeatures())])),\n",
       "                                 ('select',\n",
       "                                  SelectKBest(score_func=<function chi2 at 0x000001877B328280>)),\n",
       "                                 ('scale', StandardScaler(with_mean=False))])),\n",
       "                ('classify', LogisticRegression(max_iter=10000, tol=0.1))])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# Fit on training\n",
    "pipe_logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7972972972972973"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# Evaluate on test\n",
    "# The F1 score can be interpreted as a weighted average of the precision and recall, \n",
    "# where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision \n",
    "# and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "# F1 = 2 * (precision * recall) / (precision + recall)\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = pipe_logistic.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# we can classify new messages!\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"The bikes are heavy and unwieldy. The collection and return of the bicycle is super-comfortable because the bikes are heavy\"])\n",
    "\n",
    "pipe_logistic.predict(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# we can classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"Satisfied\"])\n",
    "\n",
    "\n",
    "pipe_logistic.predict(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "pipe_extract = FeatureUnion([(\"terms\", Pipeline([('clean', CleanText()), \n",
    "                                                 ('tfidf', TfidfVectorizer())])),\n",
    "                             (\"custom\", CustomFeatures())])\n",
    "\n",
    "# select and scale features\n",
    "pipe_select_scale = Pipeline([(\"select\", SelectKBest(score_func = chi2)),\n",
    "                              (\"scale\", StandardScaler(with_mean = False))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "# you can also use bi-grams:\n",
    "X_extract = pipe_extract.set_params(terms__tfidf__ngram_range = (1,2)).fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 697)\t0.07090144070985319\n  (0, 745)\t0.17483279959508186\n  (0, 785)\t0.043180618930796104\n  (0, 814)\t0.17483279959508186\n  (0, 1163)\t0.1648630344692586\n  (0, 1895)\t0.14402927962636455\n  (0, 1900)\t0.17483279959508186\n  (0, 1940)\t0.1648630344692586\n  (0, 1942)\t0.17483279959508186\n  (0, 2001)\t0.1523026158602164\n  (0, 2004)\t0.17483279959508186\n  (0, 2318)\t0.1648630344692586\n  (0, 2320)\t0.17483279959508186\n  (0, 2605)\t0.1307761823598249\n  (0, 2609)\t0.17483279959508186\n  (0, 2799)\t0.157789373540365\n  (0, 2800)\t0.17483279959508186\n  (0, 3315)\t0.13525918980549953\n  (0, 3323)\t0.17483279959508186\n  (0, 3509)\t0.09334204887662222\n  (0, 3529)\t0.12370252143093134\n  (0, 4020)\t0.17483279959508186\n  (0, 4021)\t0.17483279959508186\n  (0, 4343)\t0.1523026158602164\n  (0, 4346)\t0.17483279959508186\n  :\t:\n  (898, 1293)\t0.14945135091427067\n  (898, 1311)\t0.25345986443799984\n  (898, 2151)\t0.23900642479096382\n  (898, 2153)\t0.25345986443799984\n  (898, 3706)\t0.20880316378705438\n  (898, 3708)\t0.25345986443799984\n  (898, 3882)\t0.20880316378705438\n  (898, 3884)\t0.25345986443799984\n  (898, 3923)\t0.1771738498926844\n  (898, 3935)\t0.23900642479096382\n  (898, 4862)\t0.1334273238341794\n  (898, 4894)\t0.25345986443799984\n  (898, 6233)\t0.09131789001952145\n  (898, 6325)\t0.25345986443799984\n  (898, 6480)\t0.23900642479096382\n  (898, 6481)\t0.25345986443799984\n  (898, 6700)\t0.0829510509697508\n  (898, 6721)\t0.20404322788705004\n  (898, 6857)\t0.25345986443799984\n  (898, 6858)\t0.25345986443799984\n  (898, 6955)\t0.18673654039843596\n  (898, 8149)\t158.0\n  (898, 8151)\t4.0\n  (899, 3095)\t1.0\n  (899, 8149)\t5.0\n"
     ]
    }
   ],
   "source": [
    "print(X_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 222)\t1.7463975570695727\n  (0, 224)\t4.868401476553422\n  (0, 332)\t3.3310922794931095\n  (0, 391)\t3.8799422337719514\n  (0, 457)\t4.664456373753558\n  (0, 498)\t2.431404727966195\n  (0, 499)\t0.6518039044082895\n  (1, 215)\t1.955545214342361\n  (1, 216)\t4.391664155129969\n  (1, 498)\t0.7954037771785323\n  (1, 499)\t0.32590195220414475\n  (2, 190)\t3.9374599587618193\n  (2, 415)\t2.9160268437218404\n  (2, 498)\t2.205437745813203\n  (2, 499)\t2.607215617633158\n  (3, 30)\t3.467617207975343\n  (3, 35)\t19.81764758098014\n  (3, 44)\t4.029061322449084\n  (3, 254)\t17.490606015887288\n  (3, 283)\t21.01627223472825\n  (3, 294)\t1.5146934286923344\n  (3, 295)\t9.407246305477612\n  (3, 487)\t4.614820388219279\n  (3, 498)\t1.4371500064930298\n  (3, 499)\t0.6518039044082895\n  :\t:\n  (893, 494)\t2.240618278439294\n  (893, 498)\t1.6992717057905007\n  (893, 499)\t0.6518039044082895\n  (894, 347)\t2.7889851989069125\n  (894, 498)\t0.831558494323011\n  (895, 211)\t2.8248704708645893\n  (895, 397)\t1.0910163308028165\n  (895, 498)\t1.8529292536545352\n  (895, 499)\t0.9777058566124343\n  (896, 72)\t24.41599739893815\n  (896, 294)\t1.6522845847666836\n  (896, 309)\t16.430593476368912\n  (896, 352)\t2.675593080916396\n  (896, 380)\t4.5285814862791804\n  (896, 386)\t13.6708637361617\n  (896, 498)\t1.202144345053918\n  (897, 13)\t2.5695129210768552\n  (897, 191)\t6.145400961179911\n  (897, 498)\t1.8438905743684155\n  (897, 499)\t1.303607808816579\n  (898, 397)\t1.4938347656108477\n  (898, 498)\t1.4281113272069101\n  (898, 499)\t1.303607808816579\n  (899, 193)\t11.497860975131363\n  (899, 498)\t0.04519339643059842\n"
     ]
    }
   ],
   "source": [
    "# extract all features\n",
    "X_select_scale = pipe_select_scale.set_params(select__k = 500).fit_transform(X_extract, y_train)\n",
    "print(X_select_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross-validation with parameters (grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=10000, tol=0.1),\n",
       "             param_grid={'C': array([1.00000000e-04, 4.64158883e-02, 2.15443469e+01, 1.00000000e+04])},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Select best hyperparameters by cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model\n",
    "logistic = LogisticRegression(max_iter=10000, tol=0.1, solver='lbfgs')\n",
    "\n",
    "# Parameters: (np.logspace returns numbers spaced evenly on a log scale.)\n",
    "param_logistic = {\n",
    "    'C': np.logspace(-4, 4, 4)\n",
    "}\n",
    "\n",
    "# For an explanation of the 'C' parameter in scikit-learn logistic regression see:\n",
    "# https://stackoverflow.com/questions/22851316/what-is-the-inverse-of-regularization-strength-in-logistic-regression-how-shoul\n",
    "# C= 1/\\lambda where \\lambda can be assimilated to the regulatization parameter\n",
    "# you probably have seen in the lasso regression\n",
    "# Grid Search\n",
    "cv_logistic = GridSearchCV(logistic, param_logistic, cv=10, scoring='f1')\n",
    "cv_logistic.fit(X_select_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(C=0.046415888336127774, max_iter=10000, tol=0.1)\n"
     ]
    }
   ],
   "source": [
    "# See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "print(cv_logistic.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9020406477845386\n"
     ]
    }
   ],
   "source": [
    "print(cv_logistic.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('select_scale',\n",
       "                                        Pipeline(steps=[('select',\n",
       "                                                         SelectKBest(k=500,\n",
       "                                                                     score_func=<function chi2 at 0x000001877B328280>)),\n",
       "                                                        ('scale',\n",
       "                                                         StandardScaler(with_mean=False))])),\n",
       "                                       ('classify',\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           tol=0.1))]),\n",
       "             param_grid={'classify__C': array([1.e-04, 1.e+00, 1.e+04]),\n",
       "                         'select_scale__select__k': [600, 1000, 5000]},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# Pipe Logistic\n",
    "pipe_logistic = Pipeline([('select_scale', pipe_select_scale),\n",
    "                          ('classify', LogisticRegression(max_iter=10000, tol=0.1, solver='lbfgs'))])\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_logistic = {\n",
    "    'classify__C': np.logspace(-4, 4, 3),\n",
    "    'select_scale__select__k': [600, 1000, 5000]\n",
    "}\n",
    "\n",
    "cv_logistic = GridSearchCV(pipe_logistic, param_logistic, cv=10, scoring='f1')\n",
    "cv_logistic.fit(X_extract, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('select_scale',\n                 Pipeline(steps=[('select',\n                                  SelectKBest(k=5000,\n                                              score_func=<function chi2 at 0x000001877B328280>)),\n                                 ('scale', StandardScaler(with_mean=False))])),\n                ('classify',\n                 LogisticRegression(C=10000.0, max_iter=10000, tol=0.1))])\n"
     ]
    }
   ],
   "source": [
    "print(cv_logistic.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8457155973785053\n"
     ]
    }
   ],
   "source": [
    "print(cv_logistic.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8301298848126655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Pipe NB\n",
    "pipe_nb = Pipeline([('select_scale', pipe_select_scale),\n",
    "                    ('classify', MultinomialNB())])\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_nb = {\n",
    "    'classify__alpha': [0.5, 1, 10],\n",
    "    'select_scale__select__k': [600, 1000, 5000]\n",
    "}\n",
    "\n",
    "cv_nb = GridSearchCV(pipe_nb, param_nb, cv=10, scoring='f1')\n",
    "cv_nb.fit(X_extract, y_train)\n",
    "print(cv_nb.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.782608695652174"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# full pipeline\n",
    "model = Pipeline([(\"extract\", FeatureUnion([(\"terms\", Pipeline([('clean', CleanText()), \n",
    "                                                                ('tfidf', TfidfVectorizer(ngram_range = (1,2)))])),\n",
    "                                           (\"custom\", CustomFeatures())])),\n",
    "                 (\"select\", SelectKBest(score_func = chi2, k = 1000)),\n",
    "                 (\"scale\", StandardScaler(with_mean = False)),\n",
    "                 (\"classify\", MultinomialNB())]) \n",
    "\n",
    "# fitting\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# final evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# we are now able to classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"The bikes are heavy and unwieldy. The collection and return of the bicycle is super-comfortable because the bikes are heavy\"])\n",
    "\n",
    "model.predict(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# we are now able to classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"Satisfied\"])\n",
    "\n",
    "\n",
    "model.predict(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8463498495228174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Pipe SVC\n",
    "pipe_svc = Pipeline([('select_scale', pipe_select_scale),\n",
    "                     ('classify', LinearSVC(max_iter=10000, tol=0.1))])\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_svc = {\n",
    "    'classify__C': [0.01, 0.1, 1],\n",
    "    'select_scale__select__k': [600, 1000, 5000]\n",
    "}\n",
    "\n",
    "cv_svc = GridSearchCV(pipe_svc, param_svc, cv=10, scoring='f1')\n",
    "cv_svc.fit(X_extract, y_train)\n",
    "print(cv_svc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7972972972972973"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "# full pipeline\n",
    "model = Pipeline([(\"extract\", FeatureUnion([(\"terms\", Pipeline([('clean', CleanText()), \n",
    "                                                                ('tfidf', TfidfVectorizer(ngram_range = (1,2)))])),\n",
    "                                           (\"custom\", CustomFeatures())])),\n",
    "                 (\"select\", SelectKBest(score_func = chi2, k = 1000)),\n",
    "                 (\"scale\", StandardScaler(with_mean = False)),\n",
    "                 (\"classify\", LinearSVC(C = 1, max_iter=10000, tol=0.1))]) \n",
    "\n",
    "# fitting\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# final evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# we are now able to classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"The bikes are heavy and unwieldy. The collection and return of the bicycle is super-comfortable because the bikes are heavy\"])\n",
    "\n",
    "model.predict(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "# we are now able to classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"Satisfied\"])\n",
    "\n",
    "\n",
    "model.predict(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8525048282830261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Pipe RF\n",
    "pipe_rf = Pipeline([('select_scale', pipe_select_scale),\n",
    "                    ('classify', RandomForestClassifier())])\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_rf = {\n",
    "    'classify__n_estimators': [100, 200],\n",
    "    'select_scale__select__k': [600, 1000]\n",
    "}\n",
    "\n",
    "cv_rf = GridSearchCV(pipe_rf, param_rf, cv=10, scoring='f1')\n",
    "cv_rf.fit(X_extract, y_train)\n",
    "print(cv_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8053691275167785"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "# full pipeline\n",
    "model = Pipeline([(\"extract\", FeatureUnion([(\"terms\", Pipeline([('clean', CleanText()), \n",
    "                                                                ('tfidf', TfidfVectorizer(ngram_range = (1,2)))])),\n",
    "                                           (\"custom\", CustomFeatures())])),\n",
    "                 (\"select\", SelectKBest(score_func = chi2, k = 1000)),\n",
    "                 (\"scale\", StandardScaler(with_mean = False)),\n",
    "                 (\"classify\", RandomForestClassifier())]) \n",
    "\n",
    "# fitting\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# final evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# we are now able to classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"The bikes are heavy and unwieldy. The collection and return of the bicycle is super-comfortable because the bikes are heavy\"])\n",
    "\n",
    "model.predict(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# we are now able to classify new messages!\n",
    "#msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   #data    = [\"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"])\n",
    "\n",
    "msg = pd.DataFrame(columns = [\"text\"],\n",
    "                   data    = [\"Satisfied\"])\n",
    "\n",
    "\n",
    "model.predict(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long Example 1: Text clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full text for clustering\n",
    "\n",
    "This corpus contain some strings about Google and some strings about TF-IDF from Wikipedia. Just for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\"\"\n",
    "Google and Facebook are strangling the free press to death. Democracy is the loser\n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "is a numerical statistic that is intended to reflect how important \n",
    "a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Google and Facebook are strangling the free press to death. Democracy is the loser',\n",
       " \"Your 60-second guide to security stuff Google touted today at Next '18\",\n",
       " 'A Guide to Using Android Without Selling Your Soul to Google',\n",
       " 'Review: Lenovo’s Google Smart Display is pretty and intelligent',\n",
       " 'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is',\n",
       " 'Android is better than IOS',\n",
       " 'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency',\n",
       " 'is a numerical statistic that is intended to reflect how important ',\n",
       " 'a word is to a document in a collection or corpus.',\n",
       " 'It is often used as a weighting factor in searches of information retrieval',\n",
       " 'text mining, and user modeling. The tf-idf value increases proportionally',\n",
       " 'to the number of times a word appears in the document',\n",
       " 'and is offset by the frequency of the word in the corpus']"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and tokenizing\n",
    "Firstly, we must bring every chars to lowercase and remove all punctuation, because it's not important for our task, but is very harmful for clustering algorithm. \n",
    "After that, we'll split strings to array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate tf-idf for this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Google and Facebook are strangling the free press to death. Democracy is the loser'),\n",
       " (0, \"Your 60-second guide to security stuff Google touted today at Next '18\"),\n",
       " (0, 'A Guide to Using Android Without Selling Your Soul to Google'),\n",
       " (0, 'Review: Lenovo’s Google Smart Display is pretty and intelligent'),\n",
       " (0,\n",
       "  'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is'),\n",
       " (0, 'Android is better than IOS'),\n",
       " (1,\n",
       "  'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency'),\n",
       " (0, 'is a numerical statistic that is intended to reflect how important '),\n",
       " (1, 'a word is to a document in a collection or corpus.'),\n",
       " (1,\n",
       "  'It is often used as a weighting factor in searches of information retrieval'),\n",
       " (1,\n",
       "  'text mining, and user modeling. The tf-idf value increases proportionally'),\n",
       " (1, 'to the number of times a word appears in the document'),\n",
       " (1, 'and is offset by the frequency of the word in the corpus')]"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "list(zip(kmeans.fit_predict(tfidf), all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hac = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Google and Facebook are strangling the free press to death. Democracy is the loser'),\n",
       " (1, \"Your 60-second guide to security stuff Google touted today at Next '18\"),\n",
       " (1, 'A Guide to Using Android Without Selling Your Soul to Google'),\n",
       " (0, 'Review: Lenovo’s Google Smart Display is pretty and intelligent'),\n",
       " (0,\n",
       "  'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is'),\n",
       " (1, 'Android is better than IOS'),\n",
       " (0,\n",
       "  'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency'),\n",
       " (1, 'is a numerical statistic that is intended to reflect how important '),\n",
       " (0, 'a word is to a document in a collection or corpus.'),\n",
       " (0,\n",
       "  'It is often used as a weighting factor in searches of information retrieval'),\n",
       " (0,\n",
       "  'text mining, and user modeling. The tf-idf value increases proportionally'),\n",
       " (0, 'to the number of times a word appears in the document'),\n",
       " (0, 'and is offset by the frequency of the word in the corpus')]"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "list(zip(hac.fit_predict(tfidf.toarray()), all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2: Topic model (1): BikeMi survey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AndreDany\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop=set(stopwords.words('english'))\n",
    "exclude=set(string.punctuation)\n",
    "lemma=WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free=\" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free=''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized=\" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(354, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Polarity2014Reduced.csv', sep = \";\", header = 0)\n",
    "df.columns=['review','sentiment']\n",
    "df2=df[df['sentiment']==-1]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_complete=df2.iloc[0:2065,0].values.tolist()\n",
    "doc_clean=[clean(doc).split() for doc in doc_complete]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "SOME_FIXED_SEED = 42\n",
    "np.random.seed(SOME_FIXED_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(min_df=2,max_df=50,ngram_range=(1,2), token_pattern=None, tokenizer=lambda doc:doc,preprocessor=lambda doc:doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(354, 1392)\n"
     ]
    }
   ],
   "source": [
    "cv_features=cv.fit_transform(doc_clean)\n",
    "print(cv_features.shape)\n",
    "vocabulary=np.array(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['1', '1 volta', '10', ..., '√® stato', '√® troppo', '√® un'],\n",
       "      dtype='<U24')"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['1', '1 volta', '10', ..., '√® stato', '√® troppo', '√® un'],\n",
       "      dtype='<U24')"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn.decomposition LDA with 11 topics\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "TOTAL_TOPICS=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=LatentDirichletAllocation(n_components=TOTAL_TOPICS,max_iter=500,max_doc_update_iter=50,learning_method='online',batch_size=1740,learning_offset=50.,random_state=42,n_jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the transformer 'fit_transform'\n",
    "document_topics=lda_model.fit_transform(cv_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(354, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "document_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                                              Term per Topic\n",
       "Topic1   della, completamente, servizio, la bici, possibilit√†, possibilit√† di, tramite, segnalare, app, troppo            \n",
       "Topic2   servizio, bicicletta, lasciare, la bicicletta, cambio, stalli, se, le stazioni, lasciare la, la bici               \n",
       "Topic3   piene, con, sempre, al, vuote, molto, tutte, alcune, le colonnine, colonnine                                       \n",
       "Topic4   mi, da, mi √®, servizio, stazione, la bici, se, √® capitato, capitato, bikemi                                      \n",
       "Topic5   con, tempo, migliorare, al, ecc, cambio, sistema, delle bici, migliorare il, anche                                 \n",
       "Topic6   essere, con, le bici, frequenza, essere pi√π, manutenzione, bike, bici con, bici sono, troppo                      \n",
       "Topic7   pi√π spesso, al, gomme, spesso le, della, cambio, le bici, del, gonfiare, controllare                              \n",
       "Topic8   possibilit√† di, possibilit√†, segnalare, della, di segnalare, che non, dei, controllare pi√π, delle biciclette, al\n",
       "Topic9   troppo, piste, piste ciclabili, ciclabili, cambio, con, problemi, ruote, manutenzione, sgonfie                     \n",
       "Topic10  anche, le stazioni, stazione, molto, piene, servizio, tempo, del, da, cambio                                       \n",
       "Topic11  stalli, gli, centro, gli stalli, ci, nelle, di punta, punta, aumentare, le bici                                    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Term per Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Topic1</th>\n      <td>della, completamente, servizio, la bici, possibilit√†, possibilit√† di, tramite, segnalare, app, troppo</td>\n    </tr>\n    <tr>\n      <th>Topic2</th>\n      <td>servizio, bicicletta, lasciare, la bicicletta, cambio, stalli, se, le stazioni, lasciare la, la bici</td>\n    </tr>\n    <tr>\n      <th>Topic3</th>\n      <td>piene, con, sempre, al, vuote, molto, tutte, alcune, le colonnine, colonnine</td>\n    </tr>\n    <tr>\n      <th>Topic4</th>\n      <td>mi, da, mi √®, servizio, stazione, la bici, se, √® capitato, capitato, bikemi</td>\n    </tr>\n    <tr>\n      <th>Topic5</th>\n      <td>con, tempo, migliorare, al, ecc, cambio, sistema, delle bici, migliorare il, anche</td>\n    </tr>\n    <tr>\n      <th>Topic6</th>\n      <td>essere, con, le bici, frequenza, essere pi√π, manutenzione, bike, bici con, bici sono, troppo</td>\n    </tr>\n    <tr>\n      <th>Topic7</th>\n      <td>pi√π spesso, al, gomme, spesso le, della, cambio, le bici, del, gonfiare, controllare</td>\n    </tr>\n    <tr>\n      <th>Topic8</th>\n      <td>possibilit√† di, possibilit√†, segnalare, della, di segnalare, che non, dei, controllare pi√π, delle biciclette, al</td>\n    </tr>\n    <tr>\n      <th>Topic9</th>\n      <td>troppo, piste, piste ciclabili, ciclabili, cambio, con, problemi, ruote, manutenzione, sgonfie</td>\n    </tr>\n    <tr>\n      <th>Topic10</th>\n      <td>anche, le stazioni, stazione, molto, piene, servizio, tempo, del, da, cambio</td>\n    </tr>\n    <tr>\n      <th>Topic11</th>\n      <td>stalli, gli, centro, gli stalli, ci, nelle, di punta, punta, aumentare, le bici</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "# Extraqcting the most important 10 terms for each topic\n",
    "topic_terms=lda_model.components_\n",
    "top_terms=10 # number of 'top terms'\n",
    "topic_key_terms_idxs=np.argsort(-np.absolute(topic_terms), axis=1)[:,:top_terms]\n",
    "topic_keyterms=vocabulary[topic_key_terms_idxs]\n",
    "topics=[', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "topics_df=pd.DataFrame(topics,columns=['Term per Topic'], index=['Topic'+str(t) for t in range(1,TOTAL_TOPICS+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           T1        T2        T3        T4        T5        T6        T7  \\\n",
       "0    0.005348  0.005348  0.005348  0.005348  0.005348  0.005348  0.005348   \n",
       "1    0.009091  0.909084  0.009091  0.009091  0.009091  0.009091  0.009092   \n",
       "2    0.002841  0.971589  0.002841  0.002841  0.002841  0.002841  0.002841   \n",
       "3    0.015152  0.015153  0.015154  0.848456  0.015152  0.015160  0.015157   \n",
       "4    0.001567  0.001567  0.984325  0.001567  0.001567  0.001567  0.001567   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "349  0.003637  0.003637  0.003636  0.003637  0.003636  0.003637  0.003637   \n",
       "350  0.010101  0.010102  0.010102  0.898987  0.010101  0.010101  0.010102   \n",
       "351  0.018183  0.018182  0.018182  0.018182  0.018183  0.018182  0.018183   \n",
       "352  0.002392  0.002393  0.002393  0.002392  0.002392  0.002392  0.002392   \n",
       "353  0.011365  0.011364  0.011364  0.011364  0.886355  0.011365  0.011365   \n",
       "\n",
       "           T8        T9       T10       T11  \n",
       "0    0.005348  0.946523  0.005348  0.005348  \n",
       "1    0.009092  0.009093  0.009091  0.009091  \n",
       "2    0.002841  0.002841  0.002841  0.002841  \n",
       "3    0.015152  0.015156  0.015152  0.015157  \n",
       "4    0.001567  0.001568  0.001567  0.001568  \n",
       "..        ...       ...       ...       ...  \n",
       "349  0.003637  0.433846  0.003637  0.533425  \n",
       "350  0.010101  0.010101  0.010101  0.010101  \n",
       "351  0.818175  0.018182  0.018182  0.018182  \n",
       "352  0.002392  0.002393  0.976075  0.002392  \n",
       "353  0.011365  0.011364  0.011364  0.011364  \n",
       "\n",
       "[354 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T1</th>\n      <th>T2</th>\n      <th>T3</th>\n      <th>T4</th>\n      <th>T5</th>\n      <th>T6</th>\n      <th>T7</th>\n      <th>T8</th>\n      <th>T9</th>\n      <th>T10</th>\n      <th>T11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n      <td>0.946523</td>\n      <td>0.005348</td>\n      <td>0.005348</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009091</td>\n      <td>0.909084</td>\n      <td>0.009091</td>\n      <td>0.009091</td>\n      <td>0.009091</td>\n      <td>0.009091</td>\n      <td>0.009092</td>\n      <td>0.009092</td>\n      <td>0.009093</td>\n      <td>0.009091</td>\n      <td>0.009091</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002841</td>\n      <td>0.971589</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n      <td>0.002841</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.015152</td>\n      <td>0.015153</td>\n      <td>0.015154</td>\n      <td>0.848456</td>\n      <td>0.015152</td>\n      <td>0.015160</td>\n      <td>0.015157</td>\n      <td>0.015152</td>\n      <td>0.015156</td>\n      <td>0.015152</td>\n      <td>0.015157</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001567</td>\n      <td>0.001567</td>\n      <td>0.984325</td>\n      <td>0.001567</td>\n      <td>0.001567</td>\n      <td>0.001567</td>\n      <td>0.001567</td>\n      <td>0.001567</td>\n      <td>0.001568</td>\n      <td>0.001567</td>\n      <td>0.001568</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>0.003637</td>\n      <td>0.003637</td>\n      <td>0.003636</td>\n      <td>0.003637</td>\n      <td>0.003636</td>\n      <td>0.003637</td>\n      <td>0.003637</td>\n      <td>0.003637</td>\n      <td>0.433846</td>\n      <td>0.003637</td>\n      <td>0.533425</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>0.010101</td>\n      <td>0.010102</td>\n      <td>0.010102</td>\n      <td>0.898987</td>\n      <td>0.010101</td>\n      <td>0.010101</td>\n      <td>0.010102</td>\n      <td>0.010101</td>\n      <td>0.010101</td>\n      <td>0.010101</td>\n      <td>0.010101</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>0.018183</td>\n      <td>0.018182</td>\n      <td>0.018182</td>\n      <td>0.018182</td>\n      <td>0.018183</td>\n      <td>0.018182</td>\n      <td>0.018183</td>\n      <td>0.818175</td>\n      <td>0.018182</td>\n      <td>0.018182</td>\n      <td>0.018182</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>0.002392</td>\n      <td>0.002393</td>\n      <td>0.002393</td>\n      <td>0.002392</td>\n      <td>0.002392</td>\n      <td>0.002392</td>\n      <td>0.002392</td>\n      <td>0.002392</td>\n      <td>0.002393</td>\n      <td>0.976075</td>\n      <td>0.002392</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>0.011365</td>\n      <td>0.011364</td>\n      <td>0.011364</td>\n      <td>0.011364</td>\n      <td>0.886355</td>\n      <td>0.011365</td>\n      <td>0.011365</td>\n      <td>0.011365</td>\n      <td>0.011364</td>\n      <td>0.011364</td>\n      <td>0.011364</td>\n    </tr>\n  </tbody>\n</table>\n<p>354 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "dt_df=pd.DataFrame(document_topics,columns=['T'+str(i) for i in range(1,TOTAL_TOPICS+1)])\n",
    "dt_df                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Dominant Topic  Contribution%  Answer Num  \\\n",
       "Topic1              T1        0.97159         193   \n",
       "Topic2              T2        0.99209         179   \n",
       "Topic3              T3        0.98510          52   \n",
       "Topic4              T4        0.98978         328   \n",
       "Topic5              T5        0.99072          28   \n",
       "Topic6              T6        0.96503         126   \n",
       "Topic7              T7        0.98557         342   \n",
       "Topic8              T8        0.96503         174   \n",
       "Topic9              T9        0.98943         294   \n",
       "Topic10            T10        0.98864         198   \n",
       "Topic11            T11        0.99126         114   \n",
       "\n",
       "                                                                                                                       Topic  \n",
       "Topic1               della, completamente, servizio, la bici, possibilit√†, possibilit√† di, tramite, segnalare, app, troppo  \n",
       "Topic2                  servizio, bicicletta, lasciare, la bicicletta, cambio, stalli, se, le stazioni, lasciare la, la bici  \n",
       "Topic3                                          piene, con, sempre, al, vuote, molto, tutte, alcune, le colonnine, colonnine  \n",
       "Topic4                                         mi, da, mi √®, servizio, stazione, la bici, se, √® capitato, capitato, bikemi  \n",
       "Topic5                                    con, tempo, migliorare, al, ecc, cambio, sistema, delle bici, migliorare il, anche  \n",
       "Topic6                         essere, con, le bici, frequenza, essere pi√π, manutenzione, bike, bici con, bici sono, troppo  \n",
       "Topic7                                 pi√π spesso, al, gomme, spesso le, della, cambio, le bici, del, gonfiare, controllare  \n",
       "Topic8   possibilit√† di, possibilit√†, segnalare, della, di segnalare, che non, dei, controllare pi√π, delle biciclette, al  \n",
       "Topic9                        troppo, piste, piste ciclabili, ciclabili, cambio, con, problemi, ruote, manutenzione, sgonfie  \n",
       "Topic10                                         anche, le stazioni, stazione, molto, piene, servizio, tempo, del, da, cambio  \n",
       "Topic11                                      stalli, gli, centro, gli stalli, ci, nelle, di punta, punta, aumentare, le bici  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dominant Topic</th>\n      <th>Contribution%</th>\n      <th>Answer Num</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Topic1</th>\n      <td>T1</td>\n      <td>0.97159</td>\n      <td>193</td>\n      <td>della, completamente, servizio, la bici, possibilit√†, possibilit√† di, tramite, segnalare, app, troppo</td>\n    </tr>\n    <tr>\n      <th>Topic2</th>\n      <td>T2</td>\n      <td>0.99209</td>\n      <td>179</td>\n      <td>servizio, bicicletta, lasciare, la bicicletta, cambio, stalli, se, le stazioni, lasciare la, la bici</td>\n    </tr>\n    <tr>\n      <th>Topic3</th>\n      <td>T3</td>\n      <td>0.98510</td>\n      <td>52</td>\n      <td>piene, con, sempre, al, vuote, molto, tutte, alcune, le colonnine, colonnine</td>\n    </tr>\n    <tr>\n      <th>Topic4</th>\n      <td>T4</td>\n      <td>0.98978</td>\n      <td>328</td>\n      <td>mi, da, mi √®, servizio, stazione, la bici, se, √® capitato, capitato, bikemi</td>\n    </tr>\n    <tr>\n      <th>Topic5</th>\n      <td>T5</td>\n      <td>0.99072</td>\n      <td>28</td>\n      <td>con, tempo, migliorare, al, ecc, cambio, sistema, delle bici, migliorare il, anche</td>\n    </tr>\n    <tr>\n      <th>Topic6</th>\n      <td>T6</td>\n      <td>0.96503</td>\n      <td>126</td>\n      <td>essere, con, le bici, frequenza, essere pi√π, manutenzione, bike, bici con, bici sono, troppo</td>\n    </tr>\n    <tr>\n      <th>Topic7</th>\n      <td>T7</td>\n      <td>0.98557</td>\n      <td>342</td>\n      <td>pi√π spesso, al, gomme, spesso le, della, cambio, le bici, del, gonfiare, controllare</td>\n    </tr>\n    <tr>\n      <th>Topic8</th>\n      <td>T8</td>\n      <td>0.96503</td>\n      <td>174</td>\n      <td>possibilit√† di, possibilit√†, segnalare, della, di segnalare, che non, dei, controllare pi√π, delle biciclette, al</td>\n    </tr>\n    <tr>\n      <th>Topic9</th>\n      <td>T9</td>\n      <td>0.98943</td>\n      <td>294</td>\n      <td>troppo, piste, piste ciclabili, ciclabili, cambio, con, problemi, ruote, manutenzione, sgonfie</td>\n    </tr>\n    <tr>\n      <th>Topic10</th>\n      <td>T10</td>\n      <td>0.98864</td>\n      <td>198</td>\n      <td>anche, le stazioni, stazione, molto, piene, servizio, tempo, del, da, cambio</td>\n    </tr>\n    <tr>\n      <th>Topic11</th>\n      <td>T11</td>\n      <td>0.99126</td>\n      <td>114</td>\n      <td>stalli, gli, centro, gli stalli, ci, nelle, di punta, punta, aumentare, le bici</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# Column 'Contribution%' gives the max probability among the 354 \n",
    "# features (terms) for each topic\n",
    "dt_df=pd.DataFrame(document_topics,columns=['T'+str(i) for i in range(1,TOTAL_TOPICS+1)])\n",
    "pd.options.display.float_format='{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth',200)\n",
    "max_contrib_topics=dt_df.max(axis=0)\n",
    "dominant_topics=max_contrib_topics.index\n",
    "contrib_perc=max_contrib_topics.values\n",
    "document_numbers=[dt_df[dt_df[t]==max_contrib_topics.loc[t]].index[0] for t in dominant_topics]\n",
    "results_df=pd.DataFrame({'Dominant Topic':dominant_topics,'Contribution%':contrib_perc, 'Answer Num': document_numbers,'Topic':topics_df['Term per Topic']})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Dominant Topic  Contribution%  Answer Num  \\\n",
       "Topic1              T1        0.97159         193   \n",
       "Topic2              T2        0.99209         179   \n",
       "Topic3              T3        0.98510          52   \n",
       "Topic4              T4        0.98978         328   \n",
       "Topic5              T5        0.99072          28   \n",
       "Topic6              T6        0.96503         126   \n",
       "Topic7              T7        0.98557         342   \n",
       "Topic8              T8        0.96503         174   \n",
       "Topic9              T9        0.98943         294   \n",
       "Topic10            T10        0.98864         198   \n",
       "Topic11            T11        0.99126         114   \n",
       "\n",
       "                                                                                                                       Topic  \\\n",
       "Topic1               della, completamente, servizio, la bici, possibilit√†, possibilit√† di, tramite, segnalare, app, troppo   \n",
       "Topic2                  servizio, bicicletta, lasciare, la bicicletta, cambio, stalli, se, le stazioni, lasciare la, la bici   \n",
       "Topic3                                          piene, con, sempre, al, vuote, molto, tutte, alcune, le colonnine, colonnine   \n",
       "Topic4                                         mi, da, mi √®, servizio, stazione, la bici, se, √® capitato, capitato, bikemi   \n",
       "Topic5                                    con, tempo, migliorare, al, ecc, cambio, sistema, delle bici, migliorare il, anche   \n",
       "Topic6                         essere, con, le bici, frequenza, essere pi√π, manutenzione, bike, bici con, bici sono, troppo   \n",
       "Topic7                                 pi√π spesso, al, gomme, spesso le, della, cambio, le bici, del, gonfiare, controllare   \n",
       "Topic8   possibilit√† di, possibilit√†, segnalare, della, di segnalare, che non, dei, controllare pi√π, delle biciclette, al   \n",
       "Topic9                        troppo, piste, piste ciclabili, ciclabili, cambio, con, problemi, ruote, manutenzione, sgonfie   \n",
       "Topic10                                         anche, le stazioni, stazione, molto, piene, servizio, tempo, del, da, cambio   \n",
       "Topic11                                      stalli, gli, centro, gli stalli, ci, nelle, di punta, punta, aumentare, le bici   \n",
       "\n",
       "         Freq 0.9-1  \n",
       "Topic1      0.00516  \n",
       "Topic2      0.01547  \n",
       "Topic3      0.01172  \n",
       "Topic4      0.00891  \n",
       "Topic5      0.00609  \n",
       "Topic6      0.00469  \n",
       "Topic7      0.00797  \n",
       "Topic8      0.00797  \n",
       "Topic9      0.02391  \n",
       "Topic10     0.00656  \n",
       "Topic11     0.01828  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dominant Topic</th>\n      <th>Contribution%</th>\n      <th>Answer Num</th>\n      <th>Topic</th>\n      <th>Freq 0.9-1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Topic1</th>\n      <td>T1</td>\n      <td>0.97159</td>\n      <td>193</td>\n      <td>della, completamente, servizio, la bici, possibilit√†, possibilit√† di, tramite, segnalare, app, troppo</td>\n      <td>0.00516</td>\n    </tr>\n    <tr>\n      <th>Topic2</th>\n      <td>T2</td>\n      <td>0.99209</td>\n      <td>179</td>\n      <td>servizio, bicicletta, lasciare, la bicicletta, cambio, stalli, se, le stazioni, lasciare la, la bici</td>\n      <td>0.01547</td>\n    </tr>\n    <tr>\n      <th>Topic3</th>\n      <td>T3</td>\n      <td>0.98510</td>\n      <td>52</td>\n      <td>piene, con, sempre, al, vuote, molto, tutte, alcune, le colonnine, colonnine</td>\n      <td>0.01172</td>\n    </tr>\n    <tr>\n      <th>Topic4</th>\n      <td>T4</td>\n      <td>0.98978</td>\n      <td>328</td>\n      <td>mi, da, mi √®, servizio, stazione, la bici, se, √® capitato, capitato, bikemi</td>\n      <td>0.00891</td>\n    </tr>\n    <tr>\n      <th>Topic5</th>\n      <td>T5</td>\n      <td>0.99072</td>\n      <td>28</td>\n      <td>con, tempo, migliorare, al, ecc, cambio, sistema, delle bici, migliorare il, anche</td>\n      <td>0.00609</td>\n    </tr>\n    <tr>\n      <th>Topic6</th>\n      <td>T6</td>\n      <td>0.96503</td>\n      <td>126</td>\n      <td>essere, con, le bici, frequenza, essere pi√π, manutenzione, bike, bici con, bici sono, troppo</td>\n      <td>0.00469</td>\n    </tr>\n    <tr>\n      <th>Topic7</th>\n      <td>T7</td>\n      <td>0.98557</td>\n      <td>342</td>\n      <td>pi√π spesso, al, gomme, spesso le, della, cambio, le bici, del, gonfiare, controllare</td>\n      <td>0.00797</td>\n    </tr>\n    <tr>\n      <th>Topic8</th>\n      <td>T8</td>\n      <td>0.96503</td>\n      <td>174</td>\n      <td>possibilit√† di, possibilit√†, segnalare, della, di segnalare, che non, dei, controllare pi√π, delle biciclette, al</td>\n      <td>0.00797</td>\n    </tr>\n    <tr>\n      <th>Topic9</th>\n      <td>T9</td>\n      <td>0.98943</td>\n      <td>294</td>\n      <td>troppo, piste, piste ciclabili, ciclabili, cambio, con, problemi, ruote, manutenzione, sgonfie</td>\n      <td>0.02391</td>\n    </tr>\n    <tr>\n      <th>Topic10</th>\n      <td>T10</td>\n      <td>0.98864</td>\n      <td>198</td>\n      <td>anche, le stazioni, stazione, molto, piene, servizio, tempo, del, da, cambio</td>\n      <td>0.00656</td>\n    </tr>\n    <tr>\n      <th>Topic11</th>\n      <td>T11</td>\n      <td>0.99126</td>\n      <td>114</td>\n      <td>stalli, gli, centro, gli stalli, ci, nelle, di punta, punta, aumentare, le bici</td>\n      <td>0.01828</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "# This gives, for each topic, the % of features having prob >0.9\n",
    "numT1=np.count_nonzero(dt_df['T1']>0.9)\n",
    "FrT1=numT1/2133\n",
    "numT2=np.count_nonzero(dt_df['T2']>0.9)\n",
    "FrT2=numT2/2133\n",
    "numT3=np.count_nonzero(dt_df['T3']>0.9)\n",
    "FrT3=numT3/2133\n",
    "numT4=np.count_nonzero(dt_df['T4']>0.9)\n",
    "FrT4=numT4/2133\n",
    "numT5=np.count_nonzero(dt_df['T5']>0.9)\n",
    "FrT5=numT5/2133\n",
    "numT6=np.count_nonzero(dt_df['T6']>0.9)\n",
    "FrT6=numT6/2133\n",
    "numT7=np.count_nonzero(dt_df['T7']>0.9)\n",
    "FrT7=numT7/2133\n",
    "numT8=np.count_nonzero(dt_df['T8']>0.9)\n",
    "FrT8=numT8/2133\n",
    "numT9=np.count_nonzero(dt_df['T9']>0.9)\n",
    "FrT9=numT9/2133\n",
    "numT10=np.count_nonzero(dt_df['T10']>0.9)\n",
    "FrT10=numT10/2133\n",
    "numT11=np.count_nonzero(dt_df['T11']>0.9)\n",
    "FrT11=numT11/2133\n",
    "d=(FrT1,FrT2,FrT3,FrT4,FrT5,FrT6,FrT7,FrT8,FrT9,FrT10,FrT11)\n",
    "df_Fr=pd.DataFrame(data=d)\n",
    "results_df.insert(4,'Freq 0.9-1',df_Fr.values)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}